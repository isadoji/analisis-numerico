{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce59f36",
   "metadata": {},
   "source": [
    "# Métodos basados en interpolación lineal\n",
    "\n",
    "Los métodos que hemos revisado de Iteración simple y de Bisección, tienen algunos problemas:\n",
    "\n",
    "* Es posible perder raices que estén muy cercanas (si el incremento de búsqueda en $x$ es más grande que el espaciamiento entre raices)\n",
    "* Una raíz degenerada, no sería detectada\n",
    "* Algunas singularidades (polos) se confunden con raices. Por ejemplo $f(x)=\\tan x$ cambia de signo en $x = \\pm n\\pi$, $n=1,3,5,\\ldots$, pero estos no son ceros, la función no esta cruzando el eje $x$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13cd30",
   "metadata": {},
   "source": [
    "# Métodos de secante y posición falsa (*regula falsi*). \n",
    "\n",
    "Ambos métodos requieren valores iniciales de estimación de raices $x_1$ y $x_2$. Se asume que la función $f(x)$ es aproximadamente lineal cerca de la raíz. El valor mejorado de la raíz $x_3$ puede ser estimado por interpolación lineal entre $x_1$ y $x_2$.\n",
    "\n",
    "![DIV](fig/interpol-1.jpg)\n",
    "\n",
    "Con los triángulos sombreados vemos que\n",
    "$$\n",
    "\\frac{f(x_2)}{x_3-x_2} = \\frac{f(x_1)-f(x_2)}{x_2-x_1},\n",
    "$$\n",
    "entonces el valor mejorado es\n",
    "$$\n",
    "x_3 = x_2 - f(x_2)\\frac{x_2-x_1}{f(x_2)-f(x_1)}\n",
    "$$\n",
    "\n",
    "La convergencia de estos métodos no es tan buena como en el Método de Ridder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5774fc17",
   "metadata": {},
   "source": [
    "# Método de Ridder. \n",
    "\n",
    "Es una modificación del método de regula falsa. Asumiendo que la raíz esta en el intervalo $(x_1,x_2)$, calculamos $f_3 = f(x_3)$, where $x_3$ is el punto medio, como se muestra en (a).\n",
    "\n",
    "![DIV](fig/interpol-2.jpg)\n",
    "\n",
    "Luego se introduce el mapeo $g(x)=f(x)\\mathrm{e}^{(x - x_1) Q}$ donde la constante $Q$ se determina pidiendo que los puntos $(x_1,g_1)$, $(x_2,g_2)$ y $(x_3,g_3)$ (donde $g_i=g(x_i)$) pertenezcan a una línea recta, como se muestra en (b). \n",
    "\n",
    "El valor mejorado de la raíz se obtiene con interpolación lineal de $g(x)$, en lugar de usar $f(x)$\n",
    "\n",
    "¿Qué nos dice el mapeo $g(x)=f(x)\\mathrm{e}^{(x - x_1) Q}$? \n",
    "\n",
    "Primero:\n",
    "$$\n",
    "g_1=f_1, ~~~~~ g_2=f_2\\mathrm{e}^{2hQ}, ~~~~~ g_3 = f_3\\mathrm{e}^{hQ},\n",
    "$$\n",
    "donde $h = (x_2 - x_1)/2$. Entonces el requerimento de que los tres puntos caigan en la misma línea nos lleva a pedir que $g_3 = (g_1 + g_2)/2$, es decir tenemos que resolver una cuadrática en $\\mathrm{e}^{hQ}$\n",
    "$$\n",
    "f_3\\mathrm{e}^{hQ} = \\frac{1}{2} \\left(f_1 + f_2\\mathrm{e}^{2hQ}\\right) \\Longrightarrow \\mathrm{e}^{hQ} = \\frac{f_3 \\pm \\sqrt{f_3^2 -f_1f_2 }}{f_2}\n",
    "$$\n",
    "\n",
    "La interpolación lineal entre los puntos $(x_1,g_1)$ y $(x_3,g_3)$ ahora nos dá la raíz mejorada\n",
    "$$\n",
    "x_4 = x_3 - g_3 \\frac{x_3 - x_1}{g_3 - g_1} = x_3 - f_3\\mathrm{e}^{hQ} \\frac{x_3 - x_1}{f_3\\mathrm{e}^{hQ} - g_1} = x_3 \\pm   \\frac{f_3(x_3 - x_1)}{\\sqrt{f_3^2 - f_1f_2}}~~~~~\\Biggl\\{ \\begin{array}{c}\n",
    "(+) ~\\mathrm{si}~ f_1 > f_2 \\\\\n",
    "(-) ~\\mathrm{si}~ f_2 > f_1\n",
    "\\end{array} \\Biggr.\n",
    "$$\n",
    "\n",
    "El resultado anterior nos proporciona el nuevo intervalo reducido de la raíz y se aplica de nuevo esta expresión, hasta tener el resultado con la tolerancia deseada.\n",
    "\n",
    "Ventajas y desvantajas\n",
    "\n",
    "* La expresión iterativa de Ridder que acabamos de obtener tiene la propiedad de que si $x_1$ y $x_2$ abarcan a la raíz, entonces $x_4$ siempre estará contenida en el intervalo $(x_1,x_2)$.\n",
    "* La desventaja es que cada iteración requiere de dos evaluaciones de funciones.\n",
    "* Se puede mostrar que el método de Ridder converge cuadraticamente, haciéndolo más rápido que el método de la secante o que el de regula falsi.\n",
    "* Este método es el más conveniente, si tienes una función cuya derivada es difícil de calcular.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8d956",
   "metadata": {},
   "source": [
    "# Ejemplo 1: Método de Ridder: Encuentra el error del código! es typo del libro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e794f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from numpy import sign\n",
    "\n",
    "def ridder(f,a,b,tol=1.0e-9):\n",
    "  fa = f(a)\n",
    "  if fa == 0.0: return a\n",
    "  fb = f(b)\n",
    "  if fb == 0.0: return b\n",
    "  if sign(fa)!= sign(fb): c=a; fc=fa\n",
    "  for i in range(30):\n",
    "# Compute the improved root x from Ridder’s formula\n",
    "      c = 0.5*(a + b); \n",
    "      fc = f(c)\n",
    "      s = math.sqrt(fc**2 - fa*fb)\n",
    "      if s == 0.0: return None\n",
    "      dx = (c - a)*fc/s\n",
    "      if (fa - fb) < 0.0: dx = -dx\n",
    "      x = c + dx; fx = f(x)\n",
    "# Test for convergence\n",
    "  if i > 0:\n",
    "     xOld = x\n",
    "     if abs(x - xOld) < tol*max(abs(x),1.0): return x\n",
    "# Re-bracket the root as tightly as possible\n",
    "  if sign(fc) == sign(fx):\n",
    "    if sign(fa)!= sign(fx): b = x; fb = fx\n",
    "    else: a = x; fa = fx\n",
    "  else:\n",
    "    a = c; b = x; fa = fc; fb = fx\n",
    "  return None\n",
    "  print('Too many iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9575a",
   "metadata": {},
   "source": [
    "# Ejemplo 2: Método de Ridder con optimize\n",
    "\n",
    "Encuentra la raíz de la función \n",
    "$$\n",
    "f(x) = \\frac{1}{(x - 0.3)^2 + 0.01} - \\frac{1}{(x - 0.8)^2 + 0.04}.\n",
    "$$\n",
    "Puedes ver la localización aproximada de la raíz en la gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "t = np.arange(-1.0, 3.0, 0.1)\n",
    "a = (t - 0.3)**2 + 0.01\n",
    "b = (t - 0.8)**2 + 0.04\n",
    "s = 1.0/a - 1.0/b\n",
    "line, = plt.plot(t, s, lw=2)\n",
    "\n",
    "plt.annotate('raiz', xy=(0.6,0.0), xytext=(1.5, 5.0),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             )\n",
    "\n",
    "\n",
    "plt.grid(True)\n",
    "plt.ylim(-20.0, 20.0)\n",
    "\n",
    "plt.title(\"y=1/(((x-0.3)^2+0.01) - 1/((x-0.8)^2+0.04))\")\n",
    "plt.ylabel('y = f(x)')\n",
    "plt.xlabel('x')\n",
    "\n",
    "plt.savefig('raices-ridder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa076f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso de Metodo de Ridder\n",
    "from scipy import optimize\n",
    "\n",
    "def g(x): \n",
    "  a = (x - 0.3)**2 + 0.01\n",
    "  b = (x - 0.8)**2 + 0.04\n",
    "  return 1.0/a - 1.0/b\n",
    "x = ridder(g,0.0,1.0)\n",
    "print('La raiz es', '{:6.4f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd9cb4",
   "metadata": {},
   "source": [
    "# Método Newton-Raphson\n",
    "\n",
    "La expresión usada para encontrar raices con éste método, se puede obtener a partir de la representación en Serie de Taylor de la función de interés\n",
    "$$\n",
    "f(x_{i+1}) = f(x_i) + f^\\prime(x_i)(x_{i+1} -x_i) + \\mathcal{O}\\{(x_{i+1} -x_i)^2\\}.\n",
    "$$\n",
    "Entonces, si $x_{i+1}$ es una raíz de $f(x)$, esta expresión se convierte en\n",
    "$$\n",
    "0 = f(x_i) + f^\\prime(x_i)(x_{i+1} -x_i) + \\mathcal{O}\\{(x_{i+1} -x_i)^2\\}.\n",
    "$$\n",
    "Si $x_{i+1}$ es *lo suficientemente cercana* a $x_i$, los términos de órden mayor en la diferencia van a ser nulos y podemos obtener la expresión que buscamos:\n",
    "\n",
    "$$\n",
    "f(x_i)= f^\\prime(x_i)(x_{i} -x_{i+1}) \n",
    "$$$$\n",
    "\\Longrightarrow x_{i+1} = x_i - \\frac{f(x_i)}{f^\\prime(x_i)}\n",
    "$$\n",
    "\n",
    "![DIV](fig/nr-1.jpg)\n",
    "\n",
    "## Pseudocódigo\n",
    "\n",
    "El algoritmo para el método de Newton-Raphson es simple: aplica de manera repetida la expresión que obtuvimos, comenzando con un valor inicial $x_0$, hasta que se cumpla el criterio de convergencia \n",
    "$$\n",
    "|x_{i+1}-x_i| < \\varepsilon,\n",
    "$$\n",
    "donde $\\varepsilon$ es la tolerancia. Sólo se guarda el último valor de $x$ en el proceso.\n",
    "\n",
    "## Pros y cons del Método Newton-Raphson\n",
    "\n",
    "\n",
    "* es el mejor algoritmo para encontrar raices de la ecuación $f(x)=0$ puesto que es simple y rápido,\n",
    "* el algoritmo usa tanto la función $f(x)$ como su derivada $f^\\prime(x)$, entonces el método sirve cuando esta última puede calcularse,\n",
    "* el método converge de forma cuadrática, ya que el error por truncamiento de la Serie de Taylor es\n",
    "$$\n",
    "E_{i+1} = - \\frac{f^{\\prime\\prime}(x)}{2f^\\prime(x)}~E_i^2,\n",
    "$$\n",
    "donde $x$ es la raíz. Por lo tanto, el número de cifras significativas se duplica con cada iteración,\n",
    "* el método converge rápido cerca de la raíz, pero su convergencia global es pobre.\n",
    "\n",
    "La recta tangente no es siempre una aproximación aceptable de la función, como se muestra en los ejemplos:\n",
    "\n",
    "![DIV](fig/nr-2.jpg)\n",
    "\n",
    "                    !Combínalo con bisección cuando tengas este problema, y listo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modulo Newton-Raphson\n",
    "## raiz = newtonRaphson(f,df,a,b,tol=1.0e-9).\n",
    "## Encuentra la raiz de f(x) = 0 combinando Newton-Raphson\n",
    "## con biseccion. La raiz debe estar en el intervalo (a,b).\n",
    "## Los usuarios definen f(x) y su derivada df(x).\n",
    "def err(string):\n",
    "  print(string)\n",
    "  input('Press return to exit')\n",
    "  sys.exit()\n",
    "\n",
    "def newtonRaphson(f,df,a,b,tol=1.0e-9):\n",
    "  from numpy import sign\n",
    "  fa = f(a)\n",
    "  if fa == 0.0: return a\n",
    "  fb = f(b)\n",
    "  if fb == 0.0: return b\n",
    "  if sign(fa) == sign(fb): err('La raiz no esta en el intervalo')\n",
    "  x = 0.5*(a + b)\n",
    "  for i in range(30):\n",
    "    print(i)\n",
    "    fx = f(x)\n",
    "    if fx == 0.0: return x \n",
    "    if sign(fa) != sign(fx): b = x # Haz el intervalo mas pequeño\n",
    "    else: a = x\n",
    "    dfx = df(x)  \n",
    "    try: dx = -fx/dfx # Trata un paso con la expresion de Delta x\n",
    "    except ZeroDivisionError: dx = b - a # Si division diverge, intervalo afuera\n",
    "    x = x + dx # avanza en x\n",
    "    if (b - x)*(x - a) < 0.0: # Si el resultado esta fuera, usa biseccion\n",
    "      dx = 0.5*(b - a)\n",
    "      x = a + dx \n",
    "    if abs(dx) < tol*max(abs(b),1.0): return x # Checa la convergencia y sal\n",
    "  print('Too many iterations in Newton-Raphson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427206e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(x): return x**2 - 1\n",
    "def df(x): return 2*x\n",
    "root = newtonRaphson(f,df,-5.0,0)\n",
    "print('Root =',root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4beb11",
   "metadata": {},
   "source": [
    "# Ejemplo3: Newton-Raphson sencillo (ejemplo con raices degeneradas)\n",
    "\n",
    "La función\n",
    "$$\n",
    "f(x) = x^4 - 6.4 x^3 + 6.45 x^2 + 20.538 x - 31.752\n",
    "$$\n",
    "se factoriza como\n",
    "$$\n",
    "f(x) = 0.002 (x - 4) (5 x + 9) (10 x - 21)^2\n",
    "$$\n",
    "\n",
    "Lo cual indica que si lo volvemos un problema de búsqueda de raices $f(x)=0$, habrá una de ellas $x=2.1$ que sea degenerada.\n",
    "\n",
    "Usa el método Newton-Raphson para encontrarla con:\n",
    "\n",
    "* Algoritmo de clase\n",
    "* Función [newton](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton.html) de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2c1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "t = np.arange(0.0, 5.0, 0.25)\n",
    "s = t**4 - 6.4*t**3 + 6.45*t**2 + 20.538*t - 31.752\n",
    "line, = plt.plot(t, s, lw=2)\n",
    "\n",
    "plt.annotate('raiz', xy=(2.0,0.0), xytext=(3.0, 20.0),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             )\n",
    "\n",
    "\n",
    "plt.grid(True)\n",
    "plt.ylim(-40.0, 60.0)\n",
    "\n",
    "plt.title(\"y=x**4 - 6.4*x**3 + 6.45*x**2 + 20.538*x - 31.752\")\n",
    "plt.ylabel('y = f(x)')\n",
    "plt.xlabel('x')\n",
    "\n",
    "plt.savefig('raices-nr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return x**4 - 6.4*x**3 + 6.45*x**2 + 20.538*x - 31.752\n",
    "def df(x): return 4.0*x**3 - 19.2*x**2 + 12.9*x + 20.538\n",
    "\n",
    "def newtonRaphson(x,tol=1.0e-9):\n",
    "  for i in range(30):\n",
    "    dx = -f(x)/df(x)\n",
    "    x = x + dx\n",
    "    if abs(dx) < tol: return x,i\n",
    "  print('Too many iterations\\n')\n",
    "\n",
    "def newtonRaphsonDegen(x,tol=1.0e-9):\n",
    "  for i in range(30):\n",
    "    dx = -2*f(x)/df(x)\n",
    "    x = x + dx\n",
    "    if abs(dx) < tol: return x,i\n",
    "  print('Too many iterations\\n')\n",
    "\n",
    "root,numIter = newtonRaphson(2.0)\n",
    "rootd,numIterd = newtonRaphsonDegen(2.0)\n",
    "print('Root =',root)\n",
    "print('Number of iterations =',numIter)\n",
    "print('Root degen=',rootd)\n",
    "print('Number of iterations degen=',numIterd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178a445",
   "metadata": {},
   "source": [
    "# Método Newton-Raphson $n$-dim\n",
    "\n",
    "Hasta aqui, hemos abordado la solución de $f(x)= 0$. Consideremos la versión $n$-dimensional del problema $\\mathbf{f}(\\mathbf{x}) = \\mathbf{0}$, ó escrito en sus componentes\n",
    "\\begin{eqnarray*}\n",
    "f_1(x_1,x_2,\\ldots,x_n) &=& 0 \\\\\n",
    "f_2(x_1,x_2,\\ldots,x_n) &=& 0 \\\\\n",
    "\\vdots & & \\vdots \\\\\n",
    "f_n(x_1,x_2,\\ldots,x_n) &=& 0. \n",
    "\\end{eqnarray*}\n",
    "\n",
    "Resolver un sistema de $n$ ecuaciones no-lineales simultáneas es un problema con alta dificultad. \n",
    "\n",
    "El problema principal es que no existe un método seguro para aislar dentro de una región al vector solución $\\mathbf{x}$. A su vez, esto genera problemas para dar un \"buen\" valor inicial, a menos que la Física del problema lo sugiera.\n",
    "\n",
    "El método Newton-Raphson tiene buena convergencia global para ecuaciones simultáneas, si se le dá un \"buen\" valor inicial.\n",
    "\n",
    "Para obtenerlo, de nuevo comenzamos con la representación en Serie de Taylor de la función $f_i(\\mathbf{x})$ alrededor del punto $\\mathbf{x}$\n",
    "$$\n",
    "f_i(\\mathbf{x} + \\mathbf{\\Delta x}) = f_i(\\mathbf{x}) + \\sum_{j=1}^{n} \\frac{\\partial f_i}{\\partial x_j}\\Delta x_j + \\mathcal{O}\\{\\Delta x^2\\}.\n",
    "$$\n",
    "\n",
    "Si truncamos los términos $\\mathcal{O}\\{\\Delta x^2\\}$, podemos reescribir esta expresión como\n",
    "$$\n",
    "\\mathbf{f}(\\mathbf{x} + \\mathbf{\\Delta x}) = \\mathbf{f}(\\mathbf{x}) + \\mathbf{J}(\\mathbf{x})\\mathbf{\\Delta x},\n",
    "$$\n",
    "que representa una aproximación lineal (donde el vector $\\mathbf{\\Delta x}$ es la variable) de la función vectorial $\\mathbf{f}$ en la vecindad de $\\mathbf{x}$. Hemos introducido *la matríz Jacobiana* (de tamaño $n\\times n$) cuyas entradas son las derivadas parciales\n",
    "$$\n",
    "J_{ij} = \\frac{\\partial f_i}{\\partial x_j}.\n",
    "$$\n",
    "\n",
    "Consideremos que $\\mathbf{x}$ es una solución aproximada al problema $\\mathbf{f}(\\mathbf{x})=\\mathbf{0}$, y que $\\mathbf{x} + \\mathbf{\\Delta x}$ es una solución mejorada.\n",
    "\n",
    "Entonces para encontrar la \"mejora/corrección\" a la solución aproximada, tenemos que resolver la aproximación lineal anterior, de manera que $\\mathbf{f}(\\mathbf{x}+ \\mathbf{\\Delta x})=\\mathbf{0}$. Es decir,\n",
    "$$\n",
    "\\mathbf{J}(\\mathbf{x})\\mathbf{\\Delta x} = - \\mathbf{f}(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Para obtenerlo, de nuevo comenzamos con la representación en Serie de Taylor de la función $f_i(\\mathbf{x})$ alrededor del punto \n",
    "$$\n",
    "f_i(\\mathbf{x} + \\mathbf{\\Delta x}) = f_i(\\mathbf{x}) + \\sum_{j=1}^{n} \\frac{\\partial f_i}{\\partial x_j}\\Delta x_j + \\mathcal{O}\\{\\Delta x^2\\}.\n",
    "$$\n",
    "\n",
    "Como la derivación analítica de $\\partial f_i/\\partial x_j$, puede ser difícil o impráctica, podemos usar la aproximación de diferencia finita\n",
    "$$\n",
    "\\frac{\\partial f_i}{\\partial x_j} \\approx \\frac{f_i(\\mathbf{x} + \\mathbf{e}_j h) - f_i(\\mathbf{x})}{h}\n",
    "$$\n",
    "donde $h$ es un pequeño incremento de $x_j$ y $\\mathbf{e}_j$ representa un vector unitario en la dirección de $\\mathbf{x}_j$.\n",
    "\n",
    "Podemos usar esta aproximación porque el Método Newton-Raphson es poco sensible a errores en $\\mathbf{J}(\\mathbf{x})$.\n",
    "\n",
    "Esta aproximación tambien es útil porque no necesitamos codificar todas las entradas $\\partial f_i/\\partial x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3fd92",
   "metadata": {},
   "source": [
    "# Ejemplo 4: \n",
    "\n",
    "Encuentra una solución para el sistema de ecuaciones no-lineales\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\sin x + y^2 + \\ln z - 7 &=& 0 \\\\\n",
    "3 x + 2^y - z^3 + 1 &=& 0 \\\\\n",
    "x + y + z - 5 &=& 0\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "Usando el método de Newton-Raphson presentado anteriormente. Usa el valor inicial $(x, y, z) = (1, 1, 1)$.\n",
    "\n",
    "La solución encontrada con el algoritmo desarrollado es (0.59905376 2.3959314  2.00501484).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module error\n",
    "## err(string).\n",
    "## Prints ’string’ and terminates program.\n",
    "import sys\n",
    "\n",
    "def err(string):\n",
    "  print(string)\n",
    "  input('Press return to exit')\n",
    "  sys.exit()\n",
    "\n",
    "## module swap\n",
    "# swapRows(v,i,j).\n",
    "# Swaps rows i and j of a vector or matrix [v].\n",
    "# swapCols(v,i,j).\n",
    "#Swaps columns of matrix [v].\n",
    "\n",
    "def swapRows(v,i,j):\n",
    "  if len(v.shape) == 1:\n",
    "    v[i],v[j] = v[j],v[i]\n",
    "  else:\n",
    "    v[[i,j],:] = v[[j,i],:]\n",
    "\n",
    "def swapCols(v,i,j):\n",
    "  v[:,[i,j]] = v[:,[j,i]]\n",
    "\n",
    "## module gaussPivot\n",
    "# x = gaussPivot(a,b,tol=1.0e-12).\n",
    "# Solves [a]{x} = {b} by Gauss elimination with\n",
    "# scaled row pivoting\n",
    "\n",
    "import numpy as np\n",
    "#import swap\n",
    "#import error\n",
    "\n",
    "def gaussPivot(a,b,tol=1.0e-12):\n",
    "\n",
    "  n = len(b) \n",
    "  \n",
    "  # Set up scale factors\n",
    "  s = np.zeros(n)\n",
    "  for i in range(n):\n",
    "    s[i] = max(np.abs(a[i,:]))\n",
    "\n",
    "  for k in range(0,n-1): \n",
    "\n",
    "      # Row interchange, if needed\n",
    "      p = np.argmax(np.abs(a[k:n,k])/s[k:n]) + k\n",
    "      if abs(a[p,k]) < tol: error.err(\"Matrix is singular\")\n",
    "      if p != k:\n",
    "        swapRows(b,k,p)\n",
    "        swapRows(s,k,p)\n",
    "        swapRows(a,k,p)\n",
    "\n",
    "        # Elimination\n",
    "      for i in range(k+1,n):\n",
    "        if a[i,k] != 0.0:\n",
    "          lam = a[i,k]/a[k,k]\n",
    "          a[i,k+1:n] = a[i,k+1:n] - lam*a[k,k+1:n]\n",
    "          b[i] = b[i] - lam*b[k]\n",
    "            \n",
    "  if abs(a[n-1,n-1]) < tol: error.err(\"Matrix is singular\")\n",
    "\n",
    "  # Back substitution\n",
    "  b[n-1] = b[n-1]/a[n-1,n-1]\n",
    "  for k in range(n-2,-1,-1):\n",
    "    b[k] = (b[k] - np.dot(a[k,k+1:n],b[k+1:n]))/a[k,k]\n",
    "  return b\n",
    "\n",
    "\n",
    "## module newtonRaphson2\n",
    "\n",
    "# soln = newtonRaphson2(f,x,tol=1.0e-9).\n",
    "\n",
    "# Resuelve las ecuaciones simultaneas f(x) = 0 con el metodo\n",
    "# de Newton-Raphson, usando {x} como el valor inicial. \n",
    "# Nota que {f} y {x} son vectores.\n",
    "\n",
    "#import numpy as np\n",
    "#from gaussPivot import *\n",
    "import math\n",
    "\n",
    "def newtonRaphson2(f,x,tol=1.0e-9):\n",
    "  \n",
    "  def jacobian(f,x):\n",
    "    h = 1.0e-4\n",
    "    n = len(x)\n",
    "    jac = np.zeros((n,n))\n",
    "    f0 = f(x)\n",
    "    for i in range(n):\n",
    "      temp = x[i]\n",
    "      x[i] = temp + h\n",
    "      f1 = f(x)\n",
    "      x[i] = temp\n",
    "      jac[:,i] = (f1 - f0)/h\n",
    "    return jac,f0\n",
    "\n",
    "  for i in range(30):\n",
    "    jac,f0 = jacobian(f,x)\n",
    "    if math.sqrt(np.dot(f0,f0)/len(x)) < tol: return x\n",
    "    dx = gaussPivot(jac,-f0)\n",
    "    x = x + dx\n",
    "    if math.sqrt(np.dot(dx,dx)) < tol*max(max(abs(x)),1.0):\n",
    "      return x\n",
    "  print(\"Too many iterations\")\n",
    "\n",
    "##### Ejemplo 4.9\n",
    "def f(x):\n",
    "  f = np.zeros(len(x))\n",
    "  f[0] = math.sin(x[0]) + x[1]**2 + math.log(x[2]) - 7.0\n",
    "  f[1] = 3.0*x[0] + 2.0**x[1] - x[2]**3 + 1.0\n",
    "  f[2] = x[0] + x[1] + x[2] - 5.0\n",
    "  return f\n",
    "\n",
    "x = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "print(newtonRaphson2(f,x))\n",
    "\n",
    "input(\"\\nPress return to exit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
