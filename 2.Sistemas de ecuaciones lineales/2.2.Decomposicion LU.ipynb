{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f952e02",
   "metadata": {},
   "source": [
    "# Decomposición o factorización LU\n",
    "\n",
    "Se refiere a que cualquier matríz cuadrada $\\mathbf{A}$ puede expresarse como el producto de matrices triangulares inferior y superior\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{A} = \\mathbf{L~U}.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Dada una matríz cuadrada, su factorización LU no es única, a menos que impongamos constricciones en las matrices $\\mathbf{L}$ ó $\\mathbf{U}$, por ejemplo:\n",
    "\n",
    "\n",
    "* Método de decomposición       \n",
    "    1. Doolittle: $L_{ii}=1,~~~ i=1,2,\\ldots ,n$\n",
    "    2. Crout: $U_{ii}=1,~~~ i=1,2,\\ldots ,n$\n",
    "    3. Choleski: $L$ = $U^T$\n",
    "\n",
    "Después de descomponer ${A}$, las ecuaciones a resolver son $LUx$ = $b$. Entonces primero resuelves $Ly$ = $b$ para $y$= $Ux$. Despúes resuelves esta última para $x$ con el método de sustitución hacia atrás.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2cc7e3",
   "metadata": {},
   "source": [
    "## Método decomposición de Doolittle\n",
    "\n",
    "Consideremos la matríz $\\mathbf{A}$ de $3\\times 3$\n",
    "\\begin{equation}\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} \\\\\n",
    "U_{11}L_{21} & U_{12}L_{21} + U_{22} & U_{13}L_{21} + U_{23} \\\\\n",
    "U_{11}L_{31} & U_{12}L_{31} + U_{22}L_{32} & U_{13}L_{31} + U_{23}L_{32} + U_{33} \n",
    " \\end{bmatrix} \\label{eq:eleu}\n",
    "\\end{equation}\n",
    "\n",
    "que se puede factorizar en términos de $\\mathbf{LU}$ donde\n",
    "\\begin{equation}\n",
    "\\mathbf{L} = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "L_{21} & 1 & 0 \\\\\n",
    "L_{31}  & L_{32} & 1 \n",
    "\\end{bmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{U} = \\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} \\\\\n",
    "0 & U_{22} & U_{23} \\\\\n",
    "0 & 0 & U_{33} \n",
    " \\end{bmatrix}. \n",
    " \\end{equation}\n",
    "\n",
    "Podemos usar el método de eliminación de Gauss en la matriz $A$. En la fase de eliminación podemos seguir los siguientes pasos\n",
    "* Para eliminar $A_{21}$: renglón 2 $\\leftarrow$ renglón 2 - $L_{21} \\times$ renglón 1\n",
    "* Para eliminar $A_{31}$: renglón 3 $\\leftarrow$ renglón 3 - $L_{31} \\times$ renglón 1\n",
    "\n",
    "En esta etapa la matríz de la matriz $A$ va como:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{A^\\prime} = \\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} \\\\\n",
    "0 & U_{22} & U_{23} \\\\\n",
    "0 & U_{22}L_{32} & U_{23}L_{32} + U_{33} \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "En la siguiente pasada tomamos el segundo renglón de pivote y operamos\n",
    "* Para eliminar $A_{32}$: renglón 3 $\\leftarrow$ renglón 3 - $L_{32} \\times$ renglón 2\n",
    "\n",
    "para culminar con\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{A^{\\prime\\prime}} = \\mathbf{U} = \\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} \\\\\n",
    "0 & U_{22} & U_{23} \\\\\n",
    "0 & 0 & U_{33} \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Entonces, la matríz $\\mathbf{U}$ es idéntica a la que tenemos por eliminación de Gauss y la ventaja es que los elementos fuera de la diagonal de $\\mathbf{L}$ son los multiplicadores de la ecuación pivote: $L_{ij}$ es el multiplicador que eliminó a $A_{ij}$.\n",
    "\n",
    "Los multiplicadores se guardan en la porción inferior de la matríz de coeficientes a medida que son eliminados ($L_{ij}$ que reemplaza a $A_{ij}$). Los elementos de la diagonal de $\\mathbf{L}$ no se tienen que guardar, porque ya se sabe que son 1, entonces la matríz aumentada es\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\left[L\\setminus U\\right]} = \\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} \\\\\n",
    "L_{21} & U_{22} & U_{23} \\\\\n",
    "L_{31} & L_{32} & U_{33} \\end{bmatrix} \\label{eq:ldiagu}\n",
    "\\end{equation}\n",
    "\n",
    "El algoritmo queda igual que *gaussElimin*, excepto que cada multiplicador $\\lambda$ se guarda en la porción triangular inferior de $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for k in range(0,n-1):\n",
    "    for i in range(k+1,n):\n",
    "        if a[i,k] != 0.0:\n",
    "            lam = a [i,k]/a[k,k]\n",
    "            a[i,k+1:n] = a[i,k+1:n] - lam*a[k,k+1:n]\n",
    "            a[i,k] = lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3586093",
   "metadata": {},
   "source": [
    "En la fase de sustitución para encontrar la solución de $\\mathbf{Ly} = \\mathbf{b}$, donde $L_{ii}=1$ tenemos\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "y_1 & = & b_1 \\\\\n",
    "L_{21}y_1 + y_2 & = & b_2 \\\\\n",
    "&& \\vdots \\\\\n",
    "L_{k1}y_1 + L_{k2}y_2 +\\cdots +L_{k,k-1}y_{k-1} + y_k & = & b_k \\\\\n",
    "&& \\vdots\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Resolviendo la $k$-ésima ecuación para $y_k$ nos dá\n",
    "\n",
    "\\begin{equation}\n",
    "y_k = b_k - \\sum_{j=1}^{k-1}L_{kj}y_j, ~~~~~ k=2,3,\\ldots , n.\n",
    "\\end{equation}\n",
    "\n",
    "Entonces el algoritmo para sustitución **forward** es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,n):\n",
    "    b[k] = b[k] - np.dot(a[k,0:k],b[0:k])\n",
    "    b[n-1] = b[n-1]/a[n-1,nb-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36ab2c",
   "metadata": {},
   "source": [
    "Y después se usa la sustitución **backwards** para resolver $\\mathbf{Ux} = \\mathbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bf4d6",
   "metadata": {},
   "source": [
    "## Algoritmo del método decomposición Doolittle\n",
    "\n",
    "La función *LUdecomp* contiene las dos fases. La fase de decomposición entrega la matríz $\\mathbf{\\left[L\\setminus U\\right]}$. En la fase de solución, el contenido de $\\mathbf{b}$ se reemplaza por $\\mathbf{y}$ durante la sustitución **forward**. De manera análoga, la sustitución **backwards** reemplaza $\\mathbf{y}$ con la solución $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## modulo LUdecomp - Doolittle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def LUdecomp(a):\n",
    "  n = len(a)\n",
    "  for k in range(0,n-1):\n",
    "    for i in range(k+1,n):\n",
    "      if a[i,k] != 0.0:\n",
    "           lam = a [i,k]/a[k,k]\n",
    "           a[i,k+1:n] = a[i,k+1:n] - lam*a[k,k+1:n]\n",
    "           a[i,k] = lam\n",
    "  return a\n",
    "\n",
    "def LUsolve(a,b):\n",
    "  n = len(a)\n",
    "  for k in range(1,n):\n",
    "    b[k] = b[k] - np.dot(a[k,0:k],b[0:k])\n",
    "  b[n-1] = b[n-1]/a[n-1,n-1]\n",
    "  for k in range(n-2,-1,-1):\n",
    "    b[k] = (b[k] - np.dot(a[k,k+1:n],b[k+1:n]))/a[k,k]\n",
    "  return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de0dc4",
   "metadata": {},
   "source": [
    "## Comentarios sobre otros métodos\n",
    "\n",
    "* **Método de Crout.** Es igual que el de Doolittle pero ahora los $1$'s estan en la diagonal de $\\mathbf{U}$, en lugar de estar en la diagonal de $\\mathbf{L}$. El rendimiento de ambos métodos es indistinguible.\n",
    "\n",
    "* **Método de Gauss-Jordan.** Es el método de eliminación de Gauss pero llevado a su límite. En el método de eliminación de Gauss, sólo las ecuaciones por debajo del pivote se transforman. En el de Gauss-Jordan, la eliminación también se realiza en las ecuaciones arriba del pivote, hasta obtener una matríz identidad. El problema es que Gauss-Jordan requiere $\\sim n^3/2$ operaciones, mientras que eliminación de Gauss requiere menos $\\sim n^3/3$.\n",
    "\n",
    "* **Método de Choleski.** La decomposición de Choleski $\\mathbf{A} = \\mathbf{LL}^{\\mathrm{\\small T}}$ tiene las limitantes de que\n",
    "    1. $\\mathbf{A}$ tiene que ser simétrica\n",
    "    2. el proceso involucra calcular raices cuadradas de combinaciones de elementos de $\\mathbf{A}$, entonces $\\mathbf{A}$ tiene que ser positiva definida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422485f",
   "metadata": {},
   "source": [
    "# Ejemplo 1. Método de decomposición LU\n",
    "\n",
    "Usa *LUdecomp* y *LUsolve* para resolver $\\mathbf{AX=B}$ con decomposición de Doolittle y calcula el $\\det{\\mathbf{A}}$, para \n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "3 & -1 & 4 \\\\\n",
    "-2 & 0 & 5 \\\\\n",
    "7 & 2 & -2 \\end{bmatrix}~~~~~~~~~~\\mathbf{B} = \\begin{bmatrix}\n",
    "6 & -4 \\\\\n",
    "3 & 2 \\\\\n",
    "7 & -5 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Muestra que $\\det{\\mathbf{A}}= -77.0$ y que las soluciones son\n",
    "\\begin{eqnarray*}\n",
    "\\mathbf{x}_1 &=& \\left[1.~~1.~~1. \\right] \\\\\n",
    "\\mathbf{x}_2 &=& \\left[-1.~~1.~~2.3\\times 10^{-17} \\right] \\\\\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Arreglos del ejemplo\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([[ 3.0, -1.0, 4.0],\\\n",
    "              [-2.0, 0.0, 5.0],\\\n",
    "              [ 7.0, 2.0,-2.0]])\n",
    "b = np.array([[ 6.0, 3.0, 7.0],\\\n",
    "              [-4.0, 2.0, -5.0]])\n",
    "\n",
    "### Decomposici\\'on de a\n",
    "a = LUdecomp(a)\n",
    "\n",
    "### Determinante de a\n",
    "det = np.prod(np.diagonal(a))\n",
    "print(\"\\nDeterminante =\",det)\n",
    "\n",
    "### Solucion para cada columna de B\n",
    "for i in range(len(b)):\n",
    "  x = LUsolve(a,b[i])\n",
    "  print(\"Solucion x_\",i+1,\"=\",x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44740fed",
   "metadata": {},
   "source": [
    "## Introducción: Simetría y Pivoteo\n",
    "\n",
    "A veces los problemas que resolvemos nos llevan a tener matrices de coeficientes que son dispersas. Si los términos que no son cero estan agrupados alrededor de la diagonal principal, es una matríz de bandas. Por ejemplo ($X \\neq 0$)\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "X & X & 0 & 0 & 0 \\\\\n",
    "X & X & X & 0 & 0 \\\\\n",
    "0 & X & X & X & 0 \\\\\n",
    "0 & 0 & X & X & X \\\\\n",
    "0 & 0 & 0 & X & X \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Esta matríz tiene un ancho de banda de tres, porque hay cuando mucho tres elementos no nulos en cada columna: matríz *tridiagonal*.\n",
    "\n",
    "Si la matríz de bandas se descompone en la forma $\\mathbf{A}=\\mathbf{LU}$, tanto $\\mathbf{L}$ como $\\mathbf{U}$ también tienen la estructura de bandas. Por ejemplo, si descomponemos la matríz anterior, tendríamos\n",
    "$$\n",
    "\\mathbf{L} = \\begin{bmatrix}\n",
    "X & 0 & 0 & 0 & 0 \\\\\n",
    "X & X & 0 & 0 & 0 \\\\\n",
    "0 & X & X & 0 & 0 \\\\\n",
    "0 & 0 & X & X & 0 \\\\\n",
    "0 & 0 & 0 & X & X \n",
    "\\end{bmatrix} ~~~~~~~~~~ \\mathbf{U} = \\begin{bmatrix}\n",
    "X & X & 0 & 0 & 0 \\\\\n",
    "0 & X & X & 0 & 0 \\\\\n",
    "0 & 0 & X & X & 0 \\\\\n",
    "0 & 0 & 0 & X & X \\\\\n",
    "0 & 0 & 0 & 0 & X \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Entonces la estructura de bandas de la matríz de coeficientes, puede ser explotada para ahorrar memoria y tiempo de cómputo. Además, si la matríz de coeficientes es simétrica, podemos ahorrar más. ¿Qué sucede con los métodos que hemos discutido en estos casos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1e525",
   "metadata": {},
   "source": [
    "## Matríz tridiagonal y decomposición de Doolittle\n",
    "\n",
    "Considera la matríz $\\mathbf{A}$ de $n \\times n$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "d_1 & e_1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "c_1 & d_2 & e_2 & 0 & \\cdots & 0 \\\\\n",
    "0 & c_2 & d_3 & e_3 & \\cdots & 0 \\\\\n",
    "0 & 0 & c_3 & d_4 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & 0 & c_{n-1} & d_n \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Podemos guardar los elementos no-nulos de la matríz $\\mathbf{A}$ en los vectores (para $n=100$ tenemos 10,000 elementos vs $99 + 100 + 99 =298$, factor de compresión de $33:1$)\n",
    "\n",
    "$$\n",
    "\\mathbf{c}=\\begin{bmatrix}\n",
    "c_1 \\\\\n",
    "c_2 \\\\\n",
    "\\vdots \\\\\n",
    "c_{n-1}\n",
    "\\end{bmatrix}~~~~~~~~~~\\mathbf{d}=\\begin{bmatrix}\n",
    "d_1 \\\\\n",
    "d_2 \\\\\n",
    "\\vdots \\\\\n",
    "d_{n-1} \\\\\n",
    "d_n\n",
    "\\end{bmatrix}~~~~~~~~~~\\mathbf{e}=\\begin{bmatrix}\n",
    "e_1 \\\\\n",
    "e_2 \\\\\n",
    "\\vdots \\\\\n",
    "e_{n-1} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Ahora podemos aplicar decomposición LU para resolver $\\mathbf{Ax} = \\mathbf{b}$. A partir del renglón $k$-ésimo, para eliminar $c_{k-1}$ necesitamos\n",
    "1. renglón $k$ $\\leftarrow$ renglón $k$ $- \\frac{c_{k-1}}{d_{k-1}}\\times$ renglón $(k-1)$, $k=2,3,\\ldots , n$\n",
    "\n",
    "1. $d_k$ $\\leftarrow$ $d_k$ $- \\frac{c_{k-1}}{d_{k-1}}\\times$ $e_{k-1}$, $k=2,3,\\ldots , n$\n",
    "\n",
    "3. $e_k$ no se afecta\n",
    "\n",
    "Para terminar con la decomposición de Doolittle de la forma $\\mathbf{\\left[L\\setminus U\\right]}$, guardamos el factor $\\lambda = c_{k-1}/d_{k-1}$ en el lugar que ocupaba previamente $c_{k-1} \\leftarrow \\frac{c_{k-1}}{d_{k-1}}$. Entonces el algoritmo es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,n):\n",
    "    lam = c[k-1]/d[k-1]\n",
    "    d[k] = d[k] - lam*e[k-1]\n",
    "    c[k-1] = lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5cf74",
   "metadata": {},
   "source": [
    "Para la solución sucesiva del sistema $\\mathbf{Ly} = \\mathbf{b}$ y luego $\\mathbf{Ux} = \\mathbf{y}$. Comenzamos con $\\mathbf{Ly} = \\mathbf{b}$\n",
    "\n",
    "![DIV](fig/dollitle1.jpg)\n",
    "\n",
    "y resolvemos para $\\mathbf{y}$ con sustitución **forward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,n):\n",
    "    b[k] = b[k] - c[k-1]*b[k-1]\n",
    "    b[n-1] = b[n-1]/d[n-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c27846",
   "metadata": {},
   "source": [
    "Para $\\mathbf{Ux} = \\mathbf{y}$ trabajaremos con\n",
    "\n",
    "![DIV](fig/dollitle2.jpg)\n",
    "\n",
    "y resolvemos para $\\mathbf{x}$ con sustitución *backward*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(n-2,-1,-1):\n",
    "    b[k] = (b[k] - e[k]*b[k+1])/d[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac89be",
   "metadata": {},
   "source": [
    "Así, el algoritmo con funciones *LUdecomp3* y *LUsolve3* para las fases de decomposición y solución de una matríz tridiagonal es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45139583",
   "metadata": {},
   "outputs": [],
   "source": [
    "## modulo LUdecomp3\n",
    "''' c,d,e = LUdecomp3(c,d,e).\n",
    "Decomposicion LU de la matriz tridiagonal [c\\d\\e]. La salida\n",
    "{c},{d} y {e} son las diagonales de la matriz decompuesta.\n",
    "x = LUsolve(c,d,e,b).\n",
    "Resuelve [c\\d\\e]{x} = {b}, donde {c}, {d} y {e} son los vectores\n",
    "que da LUdecomp3.\n",
    "'''\n",
    "\n",
    "def LUdecomp3(c,d,e):\n",
    "  n = len(d)\n",
    "  for k in range(1,n):\n",
    "    lam = c[k-1]/d[k-1]\n",
    "    d[k] = d[k] - lam*e[k-1]\n",
    "    c[k-1] = lam\n",
    "  return c,d,e\n",
    "\n",
    "def LUsolve3(c,d,e,b):\n",
    "  n = len(d)\n",
    "  for k in range(1,n):\n",
    "    b[k] = b[k] - c[k-1]*b[k-1]\n",
    "  b[n-1] = b[n-1]/d[n-1]\n",
    "  for k in range(n-2,-1,-1):\n",
    "    b[k] = (b[k] - e[k]*b[k+1])/d[k]\n",
    "  return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4df84",
   "metadata": {},
   "source": [
    "# Ejemplo 2: Decomp. de Doolittle para matríz tridiagonal\n",
    "\n",
    "Usa las funciones *LUdecomp3* y *LUsolve3* para resolver $\\mathbf{Ax} = \\mathbf{b}$, donde\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "2 & -1 & 0 & 0 & 0 \\\\\n",
    "-1 & 2 & -1 & 0 & 0 \\\\\n",
    "0 & -1 & 2 & -1 & 0 \\\\\n",
    "0 & 0 & -1 & 2 & -1 \\\\\n",
    "0 & 0 & 0 & -1 & 2 \n",
    "\\end{bmatrix} ~~~~~~~~~~ \\mathbf{b}=\\begin{bmatrix}\n",
    "5 \\\\\n",
    "-5 \\\\\n",
    "4 \\\\\n",
    "-5 \\\\\n",
    "5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "La solución es x = [2. -1. 1. -1. 2.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d = np.ones((5))*2.0\n",
    "c = np.ones((4))*(-1.0)\n",
    "b = np.array([5.0, -5.0, 4.0, -5.0, 5.0])\n",
    "e = c.copy()\n",
    "\n",
    "c,d,e = LUdecomp3(c,d,e)\n",
    "\n",
    "x = LUsolve3(c,d,e,b)\n",
    "\n",
    "print(\"\\nx =\\n\",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e0c2e",
   "metadata": {},
   "source": [
    "## Pivoteo\n",
    "\n",
    "Algunas veces el orden en el cual se presentan las ecuaciones para encontrar la solución, afectan los resultados. Por ejemplo, consideren\n",
    "\\begin{eqnarray*}\n",
    "2x_1 - x_2 &=& 1 \\\\\n",
    "-x_1 + 2x_2 - x_3 &=& 0 \\\\\n",
    "-x_2 + x_3 &=& 0\n",
    "\\end{eqnarray*}\n",
    "\n",
    "La matríz aumentada correspondiente es\n",
    "\n",
    "![DIV](fig/dollitle3.jpg)\n",
    "\n",
    "Estas ecuaciones estan en el órden correcto y no habría ningún problema para resolver el sistema con eliminación de Gauss o con descomposición LU, para encontrar que $x_1=x_2=x_3=1$.\n",
    "\n",
    "¿Qué sucede si intercambiamos la primera y la tercera ecuación?\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "-x_2 + x_3 &=& 0 \\\\\n",
    "-x_1 + 2x_2 - x_3 &=& 0 \\\\\n",
    "2x_1 - x_2 &=& 1\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Y la matríz aumentada ahora es\n",
    "\n",
    "![DIV](fig/dollitle4.jpg)\n",
    "\n",
    "Como no hemos cambiado el sistema, la solución es la misma $x_1=x_2=x_3=1$.\n",
    "Sin embargo, eliminación de Gauss va a fallar inmediatamente debido a la presencia de un elemento nulo ($A_{11}=0$) en el pivote.\n",
    "\n",
    "Vemos entonces que es escencial, reordenar las ecuaciones <font color='red'>durante</font> la fase de eliminación. Pero este *pivoteo* o reordenamiento de renglones, también será necesario cuando los elementos sean pequeños en comparación con otros elementos. Por ejemplo,\n",
    "\n",
    "![DIV](fig/dollitle5.jpg)\n",
    "\n",
    "que son iguales, pero hemos reemplazado el primer $0$ por un elemento pequeño $\\varepsilon$. En el límite de $\\varepsilon \\to 0$, las soluciones a estos dos sistemas deben ser idénticas.\n",
    "\n",
    "Después de primera ronda de eliminación de Gauss, queda\n",
    "\n",
    "![DIV](fig/dollitle6.jpg)\n",
    "\n",
    "\n",
    "Para valores suficientemente pequeños, los $1/\\varepsilon$ dominan, entonces realmente se guardan como:\n",
    "\n",
    "![DIV](fig/dollitle7.jpg)\n",
    "\n",
    "Vemos que la segunda y tercera ecuación se contradicen y el proceso de resolución falla de nuevo. Este problema no sucedería si hubiéramos pivoteado antes de hacer eliminación de Gauss. También se muestra que para pivotear no se requiere solo un cero, sino que se requiere un criterio de pequeñéz para $\\varepsilon$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6916c5",
   "metadata": {},
   "source": [
    "## Dominancia de la diagonal\n",
    "\n",
    "Una matríz $\\mathbf{A}$ de $n \\times n$ se dice **diagonalmente dominante** si cada elemento de la diagonal satisface\n",
    "\\begin{equation}\n",
    "|A_{ii}| > \\sum_{j(\\neq i)=1}^{n} |A_{ij}| ~~~~~~~~~ i=1,2,\\ldots ,n\n",
    "\\end{equation}\n",
    "\n",
    "Por ejemplo una matríz que NO es diagonalmente dominante es\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "-2 & 4 & -1 \\\\\n",
    "1 & -1 & 3 \\\\\n",
    "4 & -2 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "pero si cambiamos los renglones de manera cíclica\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & -2 & 1 \\\\\n",
    "-2 & 4 & -1 \\\\\n",
    "1 & -1 & 3 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "aparece la dominancia de la diagonal.\n",
    "\n",
    "Si la matríz de coeficientes del sistema de ecuaciones $\\mathbf{Ax}=\\mathbf{b}$ es diagonalmente dominante, la solución del mismo, no requiere pivoteo: la matríz ya está escrita de manera óptima.\n",
    "\n",
    "Entonces la estrategia para pivoteo debe ser siempre a favor de ordenar las ecuaciones para que la matríz de coeficientes tenga la mayor dominancia de la diagonal. Para ello podemos construir un arreglo de monitoreo, el *factor de escala del renglón* $i$\n",
    "\n",
    "\\begin{equation}\n",
    "s_i = \\overset{max}{\\mbox{$j$}} \\left|A_{ij}\\right| ~~~~~~~~~~ i=1,2,\\ldots ,n\n",
    "\\end{equation}\n",
    "\n",
    "y el valor relativo de un elemento de la matríz \n",
    "$A_{ij}$ con respecto al elemento más grande del renglón $i$ puede medirse con la razón\n",
    "\n",
    "\\begin{equation}\n",
    "r_{ij} = \\frac{|A_{ij}|}{s_i}.\n",
    "\\end{equation}\n",
    "\n",
    "Supongamos que en la fase de eliminación se llega a un punto en donde queremos trabajar con el pivote en el $k$-ésimo renglón,\n",
    "\n",
    "![DIV](fig/dollitle8.jpg)\n",
    "\n",
    "pero no lo aceptamos de inmediato como pivote, primero lo estudiamos y comparamos con los siguientes renglones para ver si no hay una mejor opción. La mejor opción es el elemento $A_{pk}$ que tiene el mayor valor relativo, es decir escogemos a $p$ tal que\n",
    "$$\n",
    "r_{pk} = \\overset{max}{\\mbox{$j$}} \\left(r_{jk} \\right), ~~~~~~ j \\geq k\n",
    "$$\n",
    "\n",
    "Hay dos desventajas de pivotear:\n",
    "\n",
    "1. aumento del costo de cómputo (se vuelve criterio importante en sistemas grandes)\n",
    "2. destrucción de propiedades de simetría o de bandas de la matríz coeficientes (aunque usualmente las de bandas diagonales, son diagonalmente dominantes)\n",
    "\n",
    "* En general, el pivoteo es contraproductivo si la matríz tiene bandas, definida positiva o simétrica.\n",
    "\n",
    "* Una alternativa al pivoteo como control de error de redondeo es usar artimética con doble precisión.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
