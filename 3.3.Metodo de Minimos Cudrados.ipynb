{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10efbd21",
   "metadata": {},
   "source": [
    "# Método de mínimos cuadrados\n",
    "\n",
    "Si los datos que se obtienen de experimentos, típicamente contienen ruido (aleatorio) debido a los errores en las mediciones. \n",
    "\n",
    "En ese caso, la meta es encontrar una curva suave que ajuste \"en promedio\" a los datos. Esta curva debe tener una forma simple (e.g. un poliniomio de grado bajo), para no reproducir el ruido. \n",
    "\n",
    "Consideremos que la función\n",
    "$$\n",
    "f(x)=f(x;a_0,a_1,\\ldots ,a_m)\n",
    "$$\n",
    "\n",
    "va a ser ajustada a los $n+1$ datos $(x_i,y_i)$ con $i=0,1,\\ldots ,n$. Esta notación implica que la función de $x$ contiene $m+1$ parámetros variables (del ajuste) $a_0,a_1,\\ldots ,a_m$, donde $m<n$.\n",
    "\n",
    "La forma de $f(x)$ se determina con criterios de la teoría asociada con el experimento del cual se obtuvo los datos para ajustar. Es decir, la única manera de hacer el ajuste, es con los parámetros, no con la forma de la función.\n",
    "\n",
    "Por ejemplo, si en los datos $y_i$ representan los desplazamientos en el tiempo $t_i$ de un sistema masa-resorte sobreamortiguado, la teoría sugiere $f(t) =a_0~t~\\exp\\{-a_1 t\\}$\n",
    "\n",
    "Para el ajuste de curvas damos dos pasos:\n",
    "\n",
    "* escoger la forma de $f(x)$, usando la teoría detrás del modelaje del problema/experimento,\n",
    "* cálculo de parámetros que producen el mejor ajuste a los datos.\n",
    "\n",
    "                       Pero, ¿qué significa \"el mejor ajuste\"?\n",
    "\n",
    "Si el ruido aleatorio esta confinado a la coordenada $y$, el ajuste del **mínimo cuadrados** que minimiza la función\n",
    "\n",
    "\\begin{equation}\n",
    "S(a_0,a_1,\\ldots ,a_m)= \\sum_{i=0}^{n} \\left[y_i - f(x_i) \\right]^2\n",
    "\\label{eq:mincuad}\n",
    "\\end{equation}\n",
    "con respecto a cada coeficiente $a_k$. \n",
    "\n",
    "Por lo tanto los valores óptimos de los parámetros estan dados por la solución a las ecuaciones\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial S}{\\partial a_k} = 0, ~~~~~~ k=0,1,\\ldots ,m,\n",
    "\\label{eq:eqsmincuad}\n",
    "\\end{equation}\n",
    "\n",
    "que en general son ecuaciones no-lineales en $a_k$.\n",
    "\n",
    "Los términos $r_i = y_i - f(x_i)$ de $S$ se llaman *resíduos* y representan la discrepancia entre los datos y la función de ajuste en $x_i$.\n",
    "\n",
    "Frecuentemente la función de ajuste se contruye como una combinación lineal de las funciones específicas $f_j(x)$ que provienen del modelaje teórico,\n",
    "$$\n",
    "f(x) = a_0 f_0(x) + a_1 f_1(x) + \\cdots + a_m f_m(x)\n",
    "$$\n",
    "en cuyo caso las soluciones de las ecuciones son lineales. Si la función de ajuste es polinomial, entonces $f_0(x)=1, f_1(x)=x, f_2(x)=x^2,$ etc.\n",
    "\n",
    "La desviación estándar de los datos en torno a la curva del ajuste, se define como\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt{\\frac{S}{n-m}}.\n",
    "\\label{eq:sigmamincuad}\n",
    "\\end{equation}\n",
    "\n",
    "Si $n=m$ NO tendremos ajuste de curva, **interpolación**. En ese caso, el numerador y el denominador de la desviación estándar se hacen cero y $\\sigma$ se indetermina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5477c",
   "metadata": {},
   "source": [
    "## Método de mínimos cuadrados: ajuste a una recta\n",
    "\n",
    "El ajuste a datos con una recta $f(x) = a + bx$ se llama **regresión lineal**. En este caso la función a minimizar es\n",
    "\n",
    "\\begin{equation}\n",
    "S(a,b)= \\sum_{i=0}^{n} \\left[y_i - f(x_i) \\right]^2 =  \\sum_{i=0}^{n} \\left[y_i - a - bx_i \\right]^2 \n",
    "\\end{equation}\n",
    "\n",
    "Las soluciones a las ecuaciones ahora son:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial S}{\\partial a} &=& \\sum_{i=0}^n -2(y_i-a-bx_i) = 2 \\left[a(n+1) + b\\sum_{i=0}^n x_i - \\sum_{i=0}^n y_i \\right] =0 \\\\\n",
    "\\frac{\\partial S}{\\partial b} &=& \\sum_{i=0}^n -2(y_i-a-bx_i)x_i = 2 \\left[a\\sum_{i=0}^n x_i + b\\sum_{i=0}^n x_i^2 - \\sum_{i=0}^n x_iy_i \\right] =0 \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Dividimos ambas ecuaciones entre $2(n+1)$ y reescribiendo las ecuaciones, tenemos:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "a + \\tilde{x}b = \\tilde{y}, ~~~~~~ \\tilde{x}a + \\left(\\frac{1}{n+1}\\sum_{i=0}^n x_i^2 \\right)b = \\frac{1}{n+1}\\sum_{i=0}^n x_i y_i.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Donde hemos introducido:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\tilde{x} = \\frac{1}{n+1}\\sum_{i=0}^n x_i, ~~~~~~ \\tilde{y}=\\frac{1}{n+1}\\sum_{i=0}^n y_i,\n",
    "\\end{eqnarray}\n",
    "\n",
    "son los valores medios de $x$ y $y$ del conjunto de datos. La solución para los parámetros es:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "a=\\frac{\\tilde{y}\\sum x_i^2 - \\tilde{x}\\sum x_i y_i}{\\sum x_i^2 - n\\tilde{x}^2} ~~~~~~ b=\\frac{\\sum x_i y_i - \\tilde{x}\\sum y_i}{\\sum x_i^2 - n\\tilde{x}^2}.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Como estas expresiones son suceptibles a errores de redondeo se usan las expresiones equivalentes menos suceptibles a errores de redondeo\n",
    "\n",
    "\\begin{eqnarray}\n",
    "b = \\frac{\\sum y_i (x_i - \\tilde{x})}{\\sum x_i (x_i - \\tilde{x})} ~~~~~~ a=\\tilde{y} - \\tilde{x}b.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba05431",
   "metadata": {},
   "source": [
    "## Método de mínimos cuadrados: ajuste de formas lineales\n",
    "\n",
    "Consideremos ahora el ajuste de mínimos cuadrados de la **forma lineal**\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = a_0 f_0(x) + a_1f_1(x) + \\cdots + a_mf_m(x) = \\sum_{j=0}^m a_j f_j(x),\n",
    "\\end{equation}\n",
    "\n",
    "donde cada $f_j(x)$ es una función predeterminada de $x$ de una *base* de funciones. Sustituyendo en $S$ tenemos:\n",
    "\n",
    "\\begin{equation}\n",
    "S = \\sum_{i=0}^{n} \\left[y_i - \\sum_{j=0}^m a_j~f_j(x_i) \\right]^2. \n",
    "\\end{equation}\n",
    "\n",
    "Las soluciones a las eciaciones ahora son:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial S}{\\partial a_k} &=& -2 \\left\\{ \\sum_{i=0}^n \\left[y_i - \\sum_{j=0}^m a_j f_j(x_i) \\right] f_k(x_i) \\right\\} = 0, ~~~~~ k=0,1,\\ldots,m.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Reescribimos la expresión anterior e intercambiamos el órden de la suma, obtenemos:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    " \\sum_{j=0}^m \\left[ \\sum_{i=0}^n f_j(x_i)f_k(x_i)\\right] a_j = \\sum_{i=0}^n f_k(x_i) y_i, ~~~~~ k=0,1,\\ldots,m.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "En notación matricial estas ecuaciones (llamadas *ecuaciones normales*) son:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{Aa} = \\mathbf{b}\n",
    "\\end{eqnarray}\n",
    "donde ($A_{kj} = A_{jk}$)\n",
    "\\begin{equation}\n",
    "A_{kj} = \\sum_{i=0}^n f_j(x_i)f_k(x_i),~~~~~~ b_k= \\sum_{i=0}^n f_k(x_i) y_i, \\label{asbs}\n",
    "\\end{equation}\n",
    "\n",
    "que se resuelven con los métodos para resolver sistema de ecuaciones lineales, por ejemplo, el método de Gauss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5884f4",
   "metadata": {},
   "source": [
    "## Método de mínimos cuadrados: ajuste polinomial\n",
    "\n",
    "\n",
    "Una forma lineal común es la polinomial. Si el grado del polinomio es $m$, tenemos $f(x)=\\sum_{j=0}^m a_j x^j$. En este caso las funciones que forman la base son:\n",
    "\n",
    "\\begin{equation}\n",
    "f_j(x) = x^j ~~~~~~~~~~ j=0,1,\\ldots,m,\n",
    "\\end{equation}\n",
    "\n",
    "de tal manera que:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "A_{kj} = \\sum_{i=0}^n x_i^{j+k},~~~~~~ b_k= \\sum_{i=0}^n x_i^k y_i,\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "n & \\sum x_i & \\sum x_i^2 & \\cdots & \\sum x_i^m \\\\\n",
    "\\sum x_i & \\sum x_i^2 & \\sum x_i^3 & \\cdots & \\sum x_i^{m+1} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\sum x_i^{m-1} & \\sum x_i^m & \\sum x_i^{m+1} & \\cdots & \\sum x_i^{2m}\n",
    "\\end{bmatrix},~~\\mathbf{b} = \\begin{bmatrix}\n",
    "\\sum y_i \\\\\n",
    "\\sum x_i y_i \\\\\n",
    "\\vdots \\\\\n",
    "\\sum x_i^m y_i\n",
    "\\end{bmatrix}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Las ecuaciones normales son más singulares con el aumento de $m$. Pero los polinomios de órden bajo son los que usamos para el ajuste de curvas, porque los de órden alto tienden a reproducir el ruido de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4b75d",
   "metadata": {},
   "source": [
    "# Ejemplo 1: Método de mínimos cudrados\n",
    "\n",
    "Encontar el polinomio cuadrático que se ajusta a los siguentes datos:\n",
    "\n",
    "x | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "\n",
    "y | 2 | 8 | 14 | 28 | 39 | 62 |  \n",
    "\n",
    "1. Para el arreglo de datos $x$ y $y$ construye la matriz cuadrada y los vectores del sistema de n+1 dimensiones\n",
    "2. Mediante el uso de dos bucles anidados $i$ y $j$, define los elementos de la matriz $A$, prestando atención a la relación entre la posición de cada elemento y la potencia de su $x_i$, ya que la potencia = número de fila + número de columna considerando que los índices de filas y columnas en Python comienzan desde 0. Entonce, a potencia de $x_i$ en cada fila de $b$ es igual al número de fila.\n",
    "3. Al final de los bucles, el sistema se puede resolver para los  vectors de los coeficientes del polinomio mediante el uso de un método numérico.\n",
    "\n",
    "La función **polyFit** construye y resuelve las ecuaciones normales para los coeficientes de un polinomio de grado $m$. Esta función regresa los coeficientes del polinomio. Los coeficientes $n, \\sum x_i, \\sum x_i^2, \\ldots   \\sum x_i^m $, se guardan en un vector **s** y luego se insertan en **A**. Las ecuaciones normales se resuelven con el método de eliminación de Gauss con pivoteo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24240f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación de Gauss\n",
    "import sys\n",
    "\n",
    "def err(string):\n",
    "  print(string)\n",
    "  input('Press return to exit')\n",
    "  sys.exit()\n",
    "\n",
    "def swapRows(v,i,j):\n",
    "  if len(v.shape) == 1:\n",
    "    v[i],v[j] = v[j],v[i]\n",
    "  else:\n",
    "    v[[i,j],:] = v[[j,i],:]\n",
    "\n",
    "def swapCols(v,i,j):\n",
    "  v[:,[i,j]] = v[:,[j,i]]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def gaussPivot(a,b,tol=1.0e-12):\n",
    "\n",
    "  n = len(b) \n",
    "  s = np.zeros(n)\n",
    "  for i in range(n):\n",
    "    s[i] = max(np.abs(a[i,:]))\n",
    "\n",
    "  for k in range(0,n-1): \n",
    "      p = np.argmax(np.abs(a[k:n,k])/s[k:n]) + k\n",
    "      if abs(a[p,k]) < tol: err(\"Matrix is singular\")\n",
    "      if p != k:\n",
    "        swapRows(b,k,p)\n",
    "        swapRows(s,k,p)\n",
    "        swapRows(a,k,p)\n",
    "      for i in range(k+1,n):\n",
    "        if a[i,k] != 0.0:\n",
    "          lam = a[i,k]/a[k,k]\n",
    "          a[i,k+1:n] = a[i,k+1:n] - lam*a[k,k+1:n]\n",
    "          b[i] = b[i] - lam*b[k]\n",
    "            \n",
    "  if abs(a[n-1,n-1]) < tol: error.err(\"Matrix is singular\")\n",
    "  b[n-1] = b[n-1]/a[n-1,n-1]\n",
    "  for k in range(n-2,-1,-1):\n",
    "    b[k] = (b[k] - np.dot(a[k,k+1:n],b[k+1:n]))/a[k,k]\n",
    "  return b\n",
    "\n",
    "xData=np.array([0, 1, 2, 3, 4, 5]) #Datos en x\n",
    "yData=np.array([2, 8, 14, 28, 39, 62]) #Datos en y\n",
    "\n",
    "# Mínimos cuadrados\n",
    "\n",
    "def polyFit(xData,yData,n): #Coeficientes del polinomio\n",
    "  a = np.zeros((n+1,n+1))\n",
    "  b = np.zeros(n+1)\n",
    "  s = np.zeros(2*n+1)\n",
    "  for i in range(len(xData)):\n",
    "    temp = yData[i]\n",
    "    for j in range(n+1):\n",
    "      b[j] = b[j] + temp\n",
    "      temp = temp*xData[i]\n",
    "    temp = 1.0\n",
    "    for j in range(2*n+1):\n",
    "      s[j]=s[j]+temp\n",
    "      temp=temp*xData[i]\n",
    "  for i in range(n+1):\n",
    "    for j in range(n+1):\n",
    "      a[i,j]=s[i+j]\n",
    "  return gaussPivot(a,b)\n",
    "c=polyFit(xData,yData,2)\n",
    "\n",
    "def EvalPol(c,x): #Función que evalua polinomios \n",
    "  n=len(c)-1 #Grado del polinomio\n",
    "  p=c[n]\n",
    "  for k in range(n):\n",
    "    p=p*x+c[n-k-1]\n",
    "  return p\n",
    "import matplotlib.pyplot as plt\n",
    "x=np.arange(0,5.001,0.001)\n",
    "plt.plot(xData,yData,\"o\",label=\"Datos\")\n",
    "plt.plot(x,EvalPol(c,x),label=\"Ajuste Cuadrático\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.axvline(0,color=\"k\")\n",
    "plt.axhline(0,color=\"k\")\n",
    "plt.show()\n",
    "print(\"El ajuste polinomial cuadrático de los datos es %g+%gx+%gx**2\" %(c[0],c[1],c[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68a48e",
   "metadata": {},
   "source": [
    "# Ejemplo 2: \n",
    "\n",
    "Escribe un programa que ajuste un polinomio de grado arbitrario $m$ a los datos de la siguiente tabla. Usa el programa para determinar el grado $m$ que mejor ajuste a los datos en mínimos cuadrados, monitoreando la desviación estándar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de ajuste polinomial de grado m\n",
    "import sys\n",
    "\n",
    "def err(string):\n",
    "  print(string)\n",
    "  input('Press return to exit')\n",
    "  sys.exit()\n",
    "\n",
    "def swapRows(v,i,j):\n",
    "  if len(v.shape) == 1:\n",
    "    v[i],v[j] = v[j],v[i]\n",
    "  else:\n",
    "    v[[i,j],:] = v[[j,i],:]\n",
    "\n",
    "def swapCols(v,i,j):\n",
    "  v[:,[i,j]] = v[:,[j,i]]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def gaussPivot(a,b,tol=1.0e-12):\n",
    "\n",
    "  n = len(b) \n",
    "  s = np.zeros(n)\n",
    "  for i in range(n):\n",
    "    s[i] = max(np.abs(a[i,:]))\n",
    "\n",
    "  for k in range(0,n-1): \n",
    "      p = np.argmax(np.abs(a[k:n,k])/s[k:n]) + k\n",
    "      if abs(a[p,k]) < tol: err(\"Matrix is singular\")\n",
    "      if p != k:\n",
    "        swapRows(b,k,p)\n",
    "        swapRows(s,k,p)\n",
    "        swapRows(a,k,p)\n",
    "      for i in range(k+1,n):\n",
    "        if a[i,k] != 0.0:\n",
    "          lam = a[i,k]/a[k,k]\n",
    "          a[i,k+1:n] = a[i,k+1:n] - lam*a[k,k+1:n]\n",
    "          b[i] = b[i] - lam*b[k]\n",
    "            \n",
    "  if abs(a[n-1,n-1]) < tol: error.err(\"Matrix is singular\")\n",
    "  b[n-1] = b[n-1]/a[n-1,n-1]\n",
    "  for k in range(n-2,-1,-1):\n",
    "    b[k] = (b[k] - np.dot(a[k,k+1:n],b[k+1:n]))/a[k,k]\n",
    "  return b\n",
    "\n",
    "def polyFit(xData,yData,m): #Coeficientes del polinomio\n",
    "  a = np.zeros((m+1,m+1))\n",
    "  b = np.zeros(m+1)\n",
    "  s = np.zeros(2*m+1)\n",
    "  for i in range(len(xData)):\n",
    "    temp = yData[i]\n",
    "    for j in range(m+1):\n",
    "      b[j] = b[j] + temp\n",
    "      temp = temp*xData[i]\n",
    "    temp = 1.0\n",
    "    for j in range(2*m+1):\n",
    "      s[j]=s[j]+temp\n",
    "      temp=temp*xData[i]\n",
    "  for i in range(m+1):\n",
    "    for j in range(m+1):\n",
    "      a[i,j]=s[i+j]\n",
    "  return gaussPivot(a,b)\n",
    "\n",
    "def EvalPol(c,x): #Función que evalua polinomios \n",
    "  n=len(c)-1 #Grado del polinomio\n",
    "  p=c[n]\n",
    "  for k in range(n):\n",
    "    p=p*x+c[n-k-1]\n",
    "  return p\n",
    "\n",
    "import math\n",
    "def DesvEst(c,xData,yData,EvalPol):\n",
    "  n=len(xData)-1\n",
    "  m=len(c)-1\n",
    "  S=0\n",
    "  for i in range(n+1):\n",
    "    p=EvalPol(c,xData[i])\n",
    "    S=S+(yData[i]-p)**2\n",
    "  sigma=math.sqrt(S/(n-m))\n",
    "  return sigma\n",
    "\n",
    "xData=np.array([-0.04, 0.93, 1.95,2.90, 3.83, 5.00,5.98, 7.05, 8.21, 9.08, 10.09]) #Datos en x\n",
    "yData=np.array([-8.66, -6.44, -4.36, -3.27, -0.88, 0.87,3.31, 4.63, 6.19, 7.40, 8.85]) #Datos en y\n",
    "print(\"  Grado del polinomio       Desviación Estándar\")\n",
    "print(\"------------------------------------------------\")\n",
    "for k in range(len(xData)-1):\n",
    "  m0=k\n",
    "  c0=polyFit(xData,yData,k)\n",
    "  sigma0=DesvEst(c0,xData,yData,EvalPol)\n",
    "  print(\"           %.g                    %.8f\" %(m0,sigma0) )\n",
    "m0=0\n",
    "c0=polyFit(xData,yData,0)\n",
    "sigma0=DesvEst(c0,xData,yData,EvalPol)\n",
    "for i in range(1,len(xData)-1):\n",
    "  c=polyFit(xData,yData,i)\n",
    "  sigma=DesvEst(c,xData,yData,EvalPol)\n",
    "  if sigma<sigma0:\n",
    "    m0=i\n",
    "    c0=c\n",
    "    sigma0=sigma\n",
    "print(\"El polinomio que mejor ajusta los datos es el polinomio de grado %g\" %m0)\n",
    "print(\"f(x)=\")\n",
    "for j in range(m0+1):\n",
    "  if c0[j]<0:\n",
    "    print(\"-%gx**%g\" %(abs(c0[j]),j))\n",
    "  else:\n",
    "    print(\"+%gx**%g\" %(c0[j],j))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x=np.arange(-0.5,10.1,0.001)\n",
    "plt.plot(xData,yData,\"o\",label=\"Datos\")\n",
    "plt.plot(x,EvalPol(c0,x),label=\"Ajuste polinomial de grado %g\" %m0)\n",
    "plt.grid()\n",
    "plt.axvline(0,color=\"k\")\n",
    "plt.axhline(0,color=\"k\")\n",
    "plt.legend()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f12fe",
   "metadata": {},
   "source": [
    "# Ajuste con SciPy\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/tutorial/interpolate.html#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
